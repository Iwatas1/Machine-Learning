{"cells":[{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"92d0b544b858453796bbcebe935adc11","deepnote_cell_type":"markdown"},"source":"# Lab 2 - Math 178, Spring 2024\n\nYou are encouraged to work in groups of up to 3 total students, but each student should submit their own file. (It's fine for everyone in the group to submit the same link.)\n\nPut the full names of everyone in your group (even if you're working alone) here. This makes grading easier.\n\n**Names**: Katie Kim, Shun Iwata","block_group":"4e0d056591954bea9c0b233ec8bd25f1"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"1f1ce6f9e7d5468ca39e28cbb481da9c","deepnote_cell_type":"markdown"},"source":"The attached data is a very slightly altered form of this [Kaggle dataset](https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud/data).","block_group":"6e9fdb1a86d24be189bb9e52a82ece66"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"aaab373552af4a7a98ee4096442d372a","deepnote_cell_type":"markdown"},"source":"* Read in the attached credit card fraud data and look at its contents.  Pay particular attention to the column data types.  In this lab, we are interested in predicting the contents of the \"fraud\" column.","block_group":"5717d47eed134edc91182ddade40c71d"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"12e494acf74e4ae3abd8c085c88fcab5","deepnote_cell_type":"markdown"},"source":"## Preparing the data\n\nDivide the data into a training set and a test set.  Specify a `random_state` when you call `train_test_split`, so that you get consistent results.  I had trouble in the logistic regression section if my training set was too big, so I recommend using only 10% of the data (still a lot, 100,000 rows) as the training size.  It's possible that using even a smaller training size is appropriate.","block_group":"5d38977f51e744039e587a8d6b4cbaff"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"0ee5a92fd9cc495d8130d57bafd35061","deepnote_cell_type":"markdown"},"source":"* Imagine we always predict \"Not Fraud\".  What accuracy score (i.e., proportion correctly classified) do we get on the training set?  On the test set?  Why can there not be any overfitting here?","block_group":"36204b1bc2ad4f548222563efa7dd84c"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087745548,"execution_millis":3940,"deepnote_to_be_reexecuted":false,"cell_id":"3604a826a70441a6ab73f128ab9f9301","deepnote_cell_type":"code"},"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\n\ndf = pd.read_csv(\"card_fraud.csv\")\nvar = df.columns.to_list()\ntype(var)\nvar.remove('fraud')\nvar\n\nX_train, X_test, y_train, y_test = train_test_split(df[var], df[['fraud']], train_size = 0.1, random_state = 11)\ny_train","block_group":"e1569f4c29d64654b22b8ba456187a5b","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":1,"row_count":100000,"columns":[{"name":"fraud","dtype":"object","stats":{"unique_count":2,"nan_count":0,"categories":[{"name":"Not Fraud","count":91203},{"name":"Fraud","count":8797}]}},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"fraud":"Not Fraud","_deepnote_index_column":444737},{"fraud":"Fraud","_deepnote_index_column":957507},{"fraud":"Not Fraud","_deepnote_index_column":277798},{"fraud":"Not Fraud","_deepnote_index_column":817894},{"fraud":"Not Fraud","_deepnote_index_column":911671},{"fraud":"Not Fraud","_deepnote_index_column":653863},{"fraud":"Not Fraud","_deepnote_index_column":7125},{"fraud":"Not Fraud","_deepnote_index_column":324101},{"fraud":"Not Fraud","_deepnote_index_column":240132},{"fraud":"Not Fraud","_deepnote_index_column":333153}]},"text/plain":"            fraud\n444737  Not Fraud\n957507      Fraud\n277798  Not Fraud\n817894  Not Fraud\n911671  Not Fraud\n...           ...\n359761  Not Fraud\n728155  Not Fraud\n808016  Not Fraud\n822975  Not Fraud\n403353  Not Fraud\n\n[100000 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>444737</th>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>957507</th>\n      <td>Fraud</td>\n    </tr>\n    <tr>\n      <th>277798</th>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>817894</th>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>911671</th>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>359761</th>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>728155</th>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>808016</th>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>822975</th>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>403353</th>\n      <td>Not Fraud</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows Ã— 1 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/dd409141-dfef-4722-830f-8ffc67602df1","content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"c29cce16de23468bae7bca525cf6bf4b","deepnote_cell_type":"markdown"},"source":"above has training data accuracy, 0.912","block_group":"b133dcbd029f4e0ea3fb9b59c6db0594"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087749585,"execution_millis":34,"deepnote_to_be_reexecuted":false,"cell_id":"0fbe509cc63c4c5d9b039aa82703d313","deepnote_cell_type":"code"},"source":"len(y_test[y_test['fraud'] == 'Not Fraud'])/len(y_test)  #test data accuracy","block_group":"c7db6c2b9b754cb3a4ef42e07d99869a","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"0.91266"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/63950cc0-66c5-412f-b643-e1b26b00500b","content_dependencies":null},{"cell_type":"markdown","metadata":{"source_hash":"bbe7fc2f","execution_start":1713718784870,"execution_millis":80,"deepnote_to_be_reexecuted":false,"deepnote_app_block_visible":false,"cell_id":"a4a2d8d7acd846dabb354bf1705a74e2","deepnote_cell_type":"markdown"},"source":"* Imagine we always predict \"Not Fraud\".  What accuracy score (i.e., proportion correctly classified) do we get on the training set?  On the test set?  Why can there not be any overfitting here?","block_group":"f093af09daee4c7ba453d80d6a71d676"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"5b876d1cd86a44628c3fb258d2051b40","deepnote_cell_type":"markdown"},"source":"Since the test set and training set is randomly selected, the ratio of \"Not Fraud\" is the same for both sets. Thus if we always predict \"Not Fraud\", this is not particularly adjusting for the training data set, thus the accuracy, or the proportion of \"Not Fraud\" in the test set will be irrelevant to how the training data was. Since they will show the same accuracy (not fraud rate) due to the random selection of the test set, this clearly can't be overfitting. \n ","block_group":"ff1570a5299e41c0bfe90ee2209cd7f9"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"965c3bed6ebf45acb96392c92704b1fe","deepnote_cell_type":"markdown"},"source":"## Logistic regression - using scikit-learn\n\nFit a scikit-learn `LogisticRegression` classification model to the training data.  Because it is such a large dataset, I ran into errors/warnings during the `fit` stage if I had instantiated the `LogisticRegression` object using the default parameters.   To combat this, I used only 10% of the data in my training set, I increased the default number of iterations, and I changed the solver.  You can see the options in the `LogisticRegression` class [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).  Originally I also increased the default tolerance, but it seems like this makes the model less accurate, so try to avoid increasing the tolerance if possible.  Don't be surprised if fitting the model takes up to 5 minutes.  If you're having issues, try increasing the tolerance very slightly.","block_group":"a2deb207ecfa4ce4b4f7c87722008030"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"bd7de66f53b44d7ba864960c9b0dfb3b","deepnote_cell_type":"markdown"},"source":"* What is the accuracy score on the training set?  On the test set?  Are you concerned about overfitting?","block_group":"95717a4a808e4f728614bc00bdcf6782"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087749624,"execution_millis":5934,"deepnote_to_be_reexecuted":false,"cell_id":"d7a5f2820c9b48378fbbdbe22c772d16","deepnote_cell_type":"code"},"source":"# model = LogisticRegression(max_iter = 10**5)\nmodel = LogisticRegression(max_iter = 10**3)\nmodel.fit(X_train, np.ravel(y_train))","block_group":"96bb477c5ed94a638fc3d71e98dcf74a","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"LogisticRegression(max_iter=1000)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/b38c243d-b416-4141-9f40-bff1a53ab987","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087755641,"execution_millis":439,"deepnote_to_be_reexecuted":false,"cell_id":"d75b52fe5464498cad9c4c4e0af4b27e","deepnote_cell_type":"code"},"source":"pred = model.predict(X_train)\nscore = model.score(X_train, y_train)\nscore  #training data set","block_group":"93dbe21ad4cf40e082589cb603dc8e27","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"0.95843"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/eceb342e-66ce-4cdd-a557-ca13c3d8ad04","content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"a82804475ce94f5da3faf27fdd17adb3","deepnote_cell_type":"markdown"},"source":"Since 91.2% is actually fraud in the dataset, set this as the baseline. \naccuracy score on the training set: 95.84. This is higher than 91.2 so it is good. ","block_group":"9b56a3b081c342ec875a60aad7a35776"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087756088,"execution_millis":3400,"deepnote_to_be_reexecuted":false,"cell_id":"63e69913e9dc400d897961b4f89b313d","deepnote_cell_type":"code"},"source":"pred = model.predict(X_test)\nscore = model.score(X_test, y_test)\nscore  #test data set","block_group":"9d84105df8a840188e85b5921f27354b","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"0.9582366666666666"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/a1d80d31-873d-4fa6-9d7e-d901da20d1c6","content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"6751bba263c048c5ada55c855ba07145","deepnote_cell_type":"markdown"},"source":"Since 91.2% is actually fraud in the dataset, set this as the baseline. \naccuracy score on the test set: 95.82. This is higher than 91.2 so it is good. ","block_group":"e77c23f9e38e443483b21a4c2eebd68b"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"5b114416ffb844a7991958f226535a8d","deepnote_cell_type":"markdown"},"source":"* Evaluate the scikit-learn `confusion_matrix` function on the test data ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)).  Which entry in this confusion matrix would you focus the most on, if you were a bank?  Why? ","block_group":"56b096f291664ab3ac93ec1de79ce3c9"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087760395,"execution_millis":5747,"deepnote_to_be_reexecuted":false,"cell_id":"3d5fb7424cf144dfb35efa179dfe9a5c","deepnote_cell_type":"code"},"source":"cm = confusion_matrix(y_test, pred)\ncm","block_group":"08b2b09231c346f093ed7247c3013b0f","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"array([[ 47056,  31550],\n       [  6037, 815357]])"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/e086a01c-7a36-47a1-b4de-7d0403fd2f92","content_dependencies":null},{"cell_type":"markdown","metadata":{"cell_id":"e45755f03c74416d8e31b5abb6114860","deepnote_cell_type":"markdown"},"source":"The top right entry of the confusion matrix. It is a entry where it is a false negative where the input is actually a fraud is falsely indicated as not a fraud. Since the bank will mind the case where a fraud case is bypassed, the bank will care about this case the most. ","block_group":"b15ec94f76b341659107895ad21ed266"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"ae9135411b85478b95a03b8bcdcbf61f","deepnote_cell_type":"markdown"},"source":"## Naive Bayes - by hand\n\nOur goal in this section is to perform Naive Bayes \"by hand\" (or at least without using a scikit-learn model).  Recall that Naive Bayes is based on the following formula, taken from Section 4.4 of ISLP:\n\n![Formula 4.30](naiveBayes.png)\n\nIn our case, $k$ will represent either \"Fraud\" or \"Not Fraud\".  The function $f_{ki}(x_i)$ represents the probability (or probability density) of the i-th predictor being $x_i$ in class $k$.  To estimate these functions $f_{ki}$, we will use the first and third bullet points beneath Equation (4.30) in ISLP, according to whether the variable is a float type or a Boolean type.  The term $\\pi_k$ represents *prior* probability of class $k$ (*prior* meaning without dependence on the predictors $x_i$).\n\nStrategy:\n* We first compute the values $\\pi_k$.\n* We then (prepare to) compute the functions $f_{ki}$ when $i$ represents a float column.\n* We then (prepare to) compute the functions $f_{ki}$ when $i$ represents a Boolean column.","block_group":"fbba5c1b1e604abdaf3eed63f5ca6f4a"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766145,"execution_millis":17,"deepnote_to_be_reexecuted":false,"cell_id":"713907ab1b024b8d9d2ba05d1dc1b402","deepnote_cell_type":"code"},"source":"pi_fraud = len(y_train[y_train['fraud'] == 'Fraud'])/len(y_train)\npi_not_fraud = len(y_train[y_train['fraud'] == 'Not Fraud'])/len(y_train)","block_group":"354c4b3dab1e4f5c9a32ae40cc845bf1","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766164,"execution_millis":68,"deepnote_to_be_reexecuted":false,"cell_id":"9e085821ecc04c8587914b366e455d05","deepnote_cell_type":"code"},"source":"print(pi_fraud)\nprint(pi_not_fraud)","block_group":"3f614d1610034d8f8e504ad624f21b22","execution_count":null,"outputs":[{"name":"stdout","text":"0.08797\n0.91203\n","output_type":"stream"}],"outputs_reference":"dbtable:cell_outputs/19b54a0e-a0c6-40d7-849e-336433429ab8","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766169,"execution_millis":252,"deepnote_to_be_reexecuted":false,"cell_id":"f957900b7aca4047948280f83c386e6d","deepnote_cell_type":"code"},"source":"def bool_func(df_train, col, fraud_bool):\n\n    mydf = df_train[df_train['fraud'] == fraud_bool]\n\n    true = len(mydf[mydf[col] == True])/len(mydf)\n    false = 1-true\n\n    mylist = []\n    for val in mydf[col]:\n        if val == True:\n            mylist.append(true)\n        else:\n            mylist.append(false)\n\n    return mylist","block_group":"69273a28db074ea7807841e4e30ef283","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766174,"execution_millis":247,"deepnote_to_be_reexecuted":false,"cell_id":"4c91e605cff3468ab541e045b97b7c2a","deepnote_cell_type":"code"},"source":"X_train","block_group":"83c5e02efacf4b00b119d01a0e003cfe","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":7,"row_count":100000,"columns":[{"name":"distance_from_home","dtype":"float64","stats":{"unique_count":100000,"nan_count":0,"min":"0.0318721767498711","max":"3509.712374010665","histogram":[{"bin_start":0.0318721767498711,"bin_end":350.99992236014134,"count":99416},{"bin_start":350.99992236014134,"bin_end":701.9679725435328,"count":472},{"bin_start":701.9679725435328,"bin_end":1052.9360227269244,"count":70},{"bin_start":1052.9360227269244,"bin_end":1403.9040729103158,"count":17},{"bin_start":1403.9040729103158,"bin_end":1754.8721230937072,"count":12},{"bin_start":1754.8721230937072,"bin_end":2105.840173277099,"count":7},{"bin_start":2105.840173277099,"bin_end":2456.8082234604904,"count":4},{"bin_start":2456.8082234604904,"bin_end":2807.7762736438817,"count":1},{"bin_start":2807.7762736438817,"bin_end":3158.744323827273,"count":0},{"bin_start":3158.744323827273,"bin_end":3509.712374010665,"count":1}]}},{"name":"distance_from_last_transaction","dtype":"float64"},{"name":"ratio_to_median_purchase_price","dtype":"float64"},{"name":"repeat_retailer","dtype":"bool"},{"name":"used_chip","dtype":"bool"},{"name":"used_pin_number","dtype":"bool"},{"name":"online_order","dtype":"bool"},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"distance_from_home":8.20254779683263,"distance_from_last_transaction":0.273947264983326,"ratio_to_median_purchase_price":0.3991240329181347,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","_deepnote_index_column":444737},{"distance_from_home":202.48673621301648,"distance_from_last_transaction":1.4861936663765254,"ratio_to_median_purchase_price":6.21527650026276,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","_deepnote_index_column":957507},{"distance_from_home":23.97438153639849,"distance_from_last_transaction":4.302344391330343,"ratio_to_median_purchase_price":5.113708147235172,"repeat_retailer":"True","used_chip":"True","used_pin_number":"True","online_order":"False","_deepnote_index_column":277798},{"distance_from_home":1.050778204657945,"distance_from_last_transaction":0.5638268768547423,"ratio_to_median_purchase_price":0.3842818390812081,"repeat_retailer":"False","used_chip":"False","used_pin_number":"False","online_order":"False","_deepnote_index_column":817894},{"distance_from_home":2.426653457659478,"distance_from_last_transaction":6.746157724756723,"ratio_to_median_purchase_price":0.2674120680794355,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","_deepnote_index_column":911671},{"distance_from_home":3.366991942526937,"distance_from_last_transaction":0.270906678561351,"ratio_to_median_purchase_price":0.6322041735168126,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"True","_deepnote_index_column":653863},{"distance_from_home":23.357591803698423,"distance_from_last_transaction":0.4862674057227584,"ratio_to_median_purchase_price":4.267920252395248,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","_deepnote_index_column":7125},{"distance_from_home":60.42968206398348,"distance_from_last_transaction":119.41101375798264,"ratio_to_median_purchase_price":1.5752884076515314,"repeat_retailer":"True","used_chip":"True","used_pin_number":"False","online_order":"False","_deepnote_index_column":324101},{"distance_from_home":7.296625371219279,"distance_from_last_transaction":0.0033144192635508,"ratio_to_median_purchase_price":3.0817649582440145,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"True","_deepnote_index_column":240132},{"distance_from_home":20.47990510577761,"distance_from_last_transaction":6.7446837855175845,"ratio_to_median_purchase_price":3.4430804736624245,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"True","_deepnote_index_column":333153}]},"text/plain":"        distance_from_home  distance_from_last_transaction  \\\n444737            8.202548                        0.273947   \n957507          202.486736                        1.486194   \n277798           23.974382                        4.302344   \n817894            1.050778                        0.563827   \n911671            2.426653                        6.746158   \n...                    ...                             ...   \n359761           15.735257                        0.031037   \n728155           12.747647                        4.710128   \n808016            3.012602                        1.074755   \n822975            1.097913                        1.730297   \n403353           72.758811                        0.073200   \n\n        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n444737                        0.399124             True      False   \n957507                        6.215277             True      False   \n277798                        5.113708             True       True   \n817894                        0.384282            False      False   \n911671                        0.267412             True      False   \n...                                ...              ...        ...   \n359761                        4.406235             True      False   \n728155                        2.218541             True      False   \n808016                        1.939998             True      False   \n822975                        0.406524            False       True   \n403353                        0.245930             True      False   \n\n        used_pin_number  online_order  \n444737            False         False  \n957507            False         False  \n277798             True         False  \n817894            False         False  \n911671            False         False  \n...                 ...           ...  \n359761            False         False  \n728155             True          True  \n808016            False         False  \n822975            False          True  \n403353            False          True  \n\n[100000 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distance_from_home</th>\n      <th>distance_from_last_transaction</th>\n      <th>ratio_to_median_purchase_price</th>\n      <th>repeat_retailer</th>\n      <th>used_chip</th>\n      <th>used_pin_number</th>\n      <th>online_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>444737</th>\n      <td>8.202548</td>\n      <td>0.273947</td>\n      <td>0.399124</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>957507</th>\n      <td>202.486736</td>\n      <td>1.486194</td>\n      <td>6.215277</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>277798</th>\n      <td>23.974382</td>\n      <td>4.302344</td>\n      <td>5.113708</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>817894</th>\n      <td>1.050778</td>\n      <td>0.563827</td>\n      <td>0.384282</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>911671</th>\n      <td>2.426653</td>\n      <td>6.746158</td>\n      <td>0.267412</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>359761</th>\n      <td>15.735257</td>\n      <td>0.031037</td>\n      <td>4.406235</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>728155</th>\n      <td>12.747647</td>\n      <td>4.710128</td>\n      <td>2.218541</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>808016</th>\n      <td>3.012602</td>\n      <td>1.074755</td>\n      <td>1.939998</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>822975</th>\n      <td>1.097913</td>\n      <td>1.730297</td>\n      <td>0.406524</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>403353</th>\n      <td>72.758811</td>\n      <td>0.073200</td>\n      <td>0.245930</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows Ã— 7 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/1b6728da-34b2-4278-b4ae-2be7f07c0018","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766268,"execution_millis":369,"deepnote_to_be_reexecuted":false,"cell_id":"44a5c11d7646425cbd75e6eaed135bb1","deepnote_cell_type":"code"},"source":"import scipy.stats as st","block_group":"e824bece6d314e139e022342f418df78","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766308,"execution_millis":330,"deepnote_to_be_reexecuted":false,"cell_id":"60bd5c13d634455d9fcafe066e549677","deepnote_cell_type":"code"},"source":"def float_func(df_train, col, fraud_bool):\n\n    mydf = df_train[df_train['fraud'] == fraud_bool]\n\n    mu = mydf[col].mean()\n    sig = mydf[col].std()\n\n    mylist = []\n    for x in mydf[col]:\n        p = st.norm.pdf(x, loc = mu, scale = sig)\n        mylist.append(p)\n\n    return mylist","block_group":"47135b1738be4c2ebbf68017874375e2","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766309,"execution_millis":329,"deepnote_to_be_reexecuted":false,"cell_id":"e80cb230fd7644a886c86c991fa423da","deepnote_cell_type":"code"},"source":"","block_group":"108b40f5aea54a0a99e39257168a20bd","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"c422061374584d6b8f7c217c5b885ad8","deepnote_cell_type":"markdown"},"source":"* Define a dictionary `prior_dct` representing the two prior values $\\pi_{Fraud}$ and $\\pi_{Not Fraud}$, as in the following template.\n```\nprior_dct = {\n    \"Fraud\": ???,\n    \"Not Fraud\": ???\n}\n```\nReality check: the two values should sum to (approximately) 1.","block_group":"698256e5fe31438eb8ee104ba5d9e00f"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766309,"execution_millis":330,"deepnote_to_be_reexecuted":false,"cell_id":"45c9c05518dd436da9c9824d4ebb5a98","deepnote_cell_type":"code"},"source":"pi_fraud = len(y_train[y_train['fraud'] == 'Fraud'])/len(y_train)\npi_not_fraud = len(y_train[y_train['fraud'] == 'Not Fraud'])/len(y_train)\n\nprior_dct = {\n    \"Fraud\": pi_fraud,\n    \"Not Fraud\": pi_not_fraud\n}","block_group":"1cf97424eeca4e2e9de466f7be02e81a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"e9c79d5f8be64c5f987614b0e17297a4","deepnote_cell_type":"markdown"},"source":"* It's temporarily convenient here to have `X_train` and `y_train` together in the same DataFrame.  Concatenate these together along the columns axis and name the result `df_train`.","block_group":"85315696c2c64819b406213e02840fa9"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766310,"execution_millis":329,"deepnote_to_be_reexecuted":false,"cell_id":"8d39b5bd692646fc92c776de6cfdca45","deepnote_cell_type":"code"},"source":"df_train = pd.concat([X_train, y_train], axis=1)\ndf_train","block_group":"d30c6bab8adb43e5911c4e85bf2cb20e","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":8,"row_count":100000,"columns":[{"name":"distance_from_home","dtype":"float64","stats":{"unique_count":100000,"nan_count":0,"min":"0.0318721767498711","max":"3509.712374010665","histogram":[{"bin_start":0.0318721767498711,"bin_end":350.99992236014134,"count":99416},{"bin_start":350.99992236014134,"bin_end":701.9679725435328,"count":472},{"bin_start":701.9679725435328,"bin_end":1052.9360227269244,"count":70},{"bin_start":1052.9360227269244,"bin_end":1403.9040729103158,"count":17},{"bin_start":1403.9040729103158,"bin_end":1754.8721230937072,"count":12},{"bin_start":1754.8721230937072,"bin_end":2105.840173277099,"count":7},{"bin_start":2105.840173277099,"bin_end":2456.8082234604904,"count":4},{"bin_start":2456.8082234604904,"bin_end":2807.7762736438817,"count":1},{"bin_start":2807.7762736438817,"bin_end":3158.744323827273,"count":0},{"bin_start":3158.744323827273,"bin_end":3509.712374010665,"count":1}]}},{"name":"distance_from_last_transaction","dtype":"float64"},{"name":"ratio_to_median_purchase_price","dtype":"float64"},{"name":"repeat_retailer","dtype":"bool"},{"name":"used_chip","dtype":"bool"},{"name":"used_pin_number","dtype":"bool"},{"name":"online_order","dtype":"bool"},{"name":"fraud","dtype":"object"},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"distance_from_home":8.20254779683263,"distance_from_last_transaction":0.273947264983326,"ratio_to_median_purchase_price":0.3991240329181347,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","_deepnote_index_column":444737},{"distance_from_home":202.48673621301648,"distance_from_last_transaction":1.4861936663765254,"ratio_to_median_purchase_price":6.21527650026276,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Fraud","_deepnote_index_column":957507},{"distance_from_home":23.97438153639849,"distance_from_last_transaction":4.302344391330343,"ratio_to_median_purchase_price":5.113708147235172,"repeat_retailer":"True","used_chip":"True","used_pin_number":"True","online_order":"False","fraud":"Not Fraud","_deepnote_index_column":277798},{"distance_from_home":1.050778204657945,"distance_from_last_transaction":0.5638268768547423,"ratio_to_median_purchase_price":0.3842818390812081,"repeat_retailer":"False","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","_deepnote_index_column":817894},{"distance_from_home":2.426653457659478,"distance_from_last_transaction":6.746157724756723,"ratio_to_median_purchase_price":0.2674120680794355,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","_deepnote_index_column":911671},{"distance_from_home":3.366991942526937,"distance_from_last_transaction":0.270906678561351,"ratio_to_median_purchase_price":0.6322041735168126,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"True","fraud":"Not Fraud","_deepnote_index_column":653863},{"distance_from_home":23.357591803698423,"distance_from_last_transaction":0.4862674057227584,"ratio_to_median_purchase_price":4.267920252395248,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","_deepnote_index_column":7125},{"distance_from_home":60.42968206398348,"distance_from_last_transaction":119.41101375798264,"ratio_to_median_purchase_price":1.5752884076515314,"repeat_retailer":"True","used_chip":"True","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","_deepnote_index_column":324101},{"distance_from_home":7.296625371219279,"distance_from_last_transaction":0.0033144192635508,"ratio_to_median_purchase_price":3.0817649582440145,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"True","fraud":"Not Fraud","_deepnote_index_column":240132},{"distance_from_home":20.47990510577761,"distance_from_last_transaction":6.7446837855175845,"ratio_to_median_purchase_price":3.4430804736624245,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"True","fraud":"Not Fraud","_deepnote_index_column":333153}]},"text/plain":"        distance_from_home  distance_from_last_transaction  \\\n444737            8.202548                        0.273947   \n957507          202.486736                        1.486194   \n277798           23.974382                        4.302344   \n817894            1.050778                        0.563827   \n911671            2.426653                        6.746158   \n...                    ...                             ...   \n359761           15.735257                        0.031037   \n728155           12.747647                        4.710128   \n808016            3.012602                        1.074755   \n822975            1.097913                        1.730297   \n403353           72.758811                        0.073200   \n\n        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n444737                        0.399124             True      False   \n957507                        6.215277             True      False   \n277798                        5.113708             True       True   \n817894                        0.384282            False      False   \n911671                        0.267412             True      False   \n...                                ...              ...        ...   \n359761                        4.406235             True      False   \n728155                        2.218541             True      False   \n808016                        1.939998             True      False   \n822975                        0.406524            False       True   \n403353                        0.245930             True      False   \n\n        used_pin_number  online_order      fraud  \n444737            False         False  Not Fraud  \n957507            False         False      Fraud  \n277798             True         False  Not Fraud  \n817894            False         False  Not Fraud  \n911671            False         False  Not Fraud  \n...                 ...           ...        ...  \n359761            False         False  Not Fraud  \n728155             True          True  Not Fraud  \n808016            False         False  Not Fraud  \n822975            False          True  Not Fraud  \n403353            False          True  Not Fraud  \n\n[100000 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distance_from_home</th>\n      <th>distance_from_last_transaction</th>\n      <th>ratio_to_median_purchase_price</th>\n      <th>repeat_retailer</th>\n      <th>used_chip</th>\n      <th>used_pin_number</th>\n      <th>online_order</th>\n      <th>fraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>444737</th>\n      <td>8.202548</td>\n      <td>0.273947</td>\n      <td>0.399124</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>957507</th>\n      <td>202.486736</td>\n      <td>1.486194</td>\n      <td>6.215277</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Fraud</td>\n    </tr>\n    <tr>\n      <th>277798</th>\n      <td>23.974382</td>\n      <td>4.302344</td>\n      <td>5.113708</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>817894</th>\n      <td>1.050778</td>\n      <td>0.563827</td>\n      <td>0.384282</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>911671</th>\n      <td>2.426653</td>\n      <td>6.746158</td>\n      <td>0.267412</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>359761</th>\n      <td>15.735257</td>\n      <td>0.031037</td>\n      <td>4.406235</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>728155</th>\n      <td>12.747647</td>\n      <td>4.710128</td>\n      <td>2.218541</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>808016</th>\n      <td>3.012602</td>\n      <td>1.074755</td>\n      <td>1.939998</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>822975</th>\n      <td>1.097913</td>\n      <td>1.730297</td>\n      <td>0.406524</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>403353</th>\n      <td>72.758811</td>\n      <td>0.073200</td>\n      <td>0.245930</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Not Fraud</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows Ã— 8 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/f98939bb-59e2-409d-a2c0-d821e97b8132","content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"ddca46535d244b0aa084e09041abc3db","deepnote_cell_type":"markdown"},"source":"* Write a function `Gaussian_helper` which takes a DataFrame input `df` and two string inputs, a class `k` (which will be \"Not Fraud\" or \"Fraud\" in our case) and a column name `col` of one of the float columns.  The output should be a dictionary with keys `\"mean\"` and `\"std\"`, representing the mean and the standard deviation for the given column within the given class, as in the first bullet point after (4.30).  \n\nComment: To find the mean and standard deviation, you can use the formulas in (4.20) (take the square root of the variance to get the standard deviation), but I think it's easier to just let pandas compute these for you, using the `mean` and `std` methods of a pandas Series.  It's possible pandas will use $n$ instead of the $n-K$ in Equation (4.20), but that shouldn't be significant here because $n$ is so big and $K=2$. \n\nHere is a possible template:\n```\ndef Gaussian_helper(df, k, col):\n    output_dct = {}\n    ... # one or more lines here\n    output_dct[\"mean\"] = ...\n    output_dct[\"std\"] = ...\n    return output_dct\n```","block_group":"4b1ca6e1c57f4ec4a2bf754fed679752"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766398,"execution_millis":241,"deepnote_to_be_reexecuted":false,"cell_id":"9a2cfd81c4544f9fad7c3a7a838a7915","deepnote_cell_type":"code"},"source":"def Gaussian_helper(df, k, col):\n\n    mydf = df[df['fraud'] == k]\n\n    output_dct = {}\n    output_dct[\"mean\"] = mydf[col].mean()\n    output_dct[\"std\"] = mydf[col].std()\n\n    return output_dct","block_group":"74ed3c2fab704bb09a2825cb08779e39","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"81631c9d1b8f4893b6eee9cea78ad901","deepnote_cell_type":"markdown"},"source":"* Similarly, write a function `Boolean_helper` which takes a DataFrame input `df` and two string inputs, a class `k` (which will be \"Not Fraud\" or \"Fraud\" in our case) and a column name `col` of one of the Boolean columns.  The output should be a dictionary with keys `True` and `False`, representing the proportion of these values within the given class.  For an example, see the third bullet point after (4.30) in the textbook.\n\nComment: Make sure your keys are `bool` values, not strings.","block_group":"ecf9167355b8418eb8eb5b4df8ff4c72"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766451,"execution_millis":418,"deepnote_to_be_reexecuted":false,"cell_id":"8fb11fa80ec84695a70e4dcd3a659a8c","deepnote_cell_type":"code"},"source":"def bool_helper(df_train, k, col):\n\n    mydf = df_train[df_train['fraud'] == k]\n\n    true = len(mydf[mydf[col] == True])/len(mydf)\n    false = 1-true\n\n    output_dct = {}\n    output_dct[\"True\"] = true\n    output_dct[\"False\"] = false\n    \n    return output_dct","block_group":"f52713175a024286abfbf19b20d2da2a","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"ed99cf6c0a904cc9958ece8149deb30d","deepnote_cell_type":"markdown"},"source":"* Check your helper functions by comparing a few of their outputs to the following.  (I feel like there is probably a nice way to use the following DataFrame directly and never define the helper functions, but I did not succeed in doing that.)\n\n```\ndf_train.groupby(\"fraud\").mean()\n```","block_group":"3ca29c96a936495ab2e863e87835376e"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766452,"execution_millis":418,"deepnote_to_be_reexecuted":false,"cell_id":"2d9b1d0d44ff496eaec67b879c61711b","deepnote_cell_type":"code"},"source":"df_train.groupby(\"fraud\").mean()","block_group":"c5709d71db3347229c828fb9a26f2268","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":7,"row_count":2,"columns":[{"name":"distance_from_home","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"22.831175153939462","max":"67.11251533233086","histogram":[{"bin_start":22.831175153939462,"bin_end":27.259309171778604,"count":1},{"bin_start":27.259309171778604,"bin_end":31.687443189617742,"count":0},{"bin_start":31.687443189617742,"bin_end":36.11557720745688,"count":0},{"bin_start":36.11557720745688,"bin_end":40.54371122529602,"count":0},{"bin_start":40.54371122529602,"bin_end":44.971845243135164,"count":0},{"bin_start":44.971845243135164,"bin_end":49.399979260974305,"count":0},{"bin_start":49.399979260974305,"bin_end":53.82811327881344,"count":0},{"bin_start":53.82811327881344,"bin_end":58.25624729665258,"count":0},{"bin_start":58.25624729665258,"bin_end":62.68438131449172,"count":0},{"bin_start":62.68438131449172,"bin_end":67.11251533233086,"count":1}]}},{"name":"distance_from_last_transaction","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"4.2558134678412065","max":"11.811646222217304","histogram":[{"bin_start":4.2558134678412065,"bin_end":5.011396743278816,"count":1},{"bin_start":5.011396743278816,"bin_end":5.766980018716426,"count":0},{"bin_start":5.766980018716426,"bin_end":6.522563294154036,"count":0},{"bin_start":6.522563294154036,"bin_end":7.278146569591645,"count":0},{"bin_start":7.278146569591645,"bin_end":8.033729845029255,"count":0},{"bin_start":8.033729845029255,"bin_end":8.789313120466865,"count":0},{"bin_start":8.789313120466865,"bin_end":9.544896395904473,"count":0},{"bin_start":9.544896395904473,"bin_end":10.300479671342085,"count":0},{"bin_start":10.300479671342085,"bin_end":11.056062946779694,"count":0},{"bin_start":11.056062946779694,"bin_end":11.811646222217304,"count":1}]}},{"name":"ratio_to_median_purchase_price","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"1.4146021121300856","max":"6.0244886523047985","histogram":[{"bin_start":1.4146021121300856,"bin_end":1.8755907661475568,"count":1},{"bin_start":1.8755907661475568,"bin_end":2.3365794201650285,"count":0},{"bin_start":2.3365794201650285,"bin_end":2.7975680741824998,"count":0},{"bin_start":2.7975680741824998,"bin_end":3.258556728199971,"count":0},{"bin_start":3.258556728199971,"bin_end":3.7195453822174422,"count":0},{"bin_start":3.7195453822174422,"bin_end":4.1805340362349135,"count":0},{"bin_start":4.1805340362349135,"bin_end":4.641522690252385,"count":0},{"bin_start":4.641522690252385,"bin_end":5.102511344269857,"count":0},{"bin_start":5.102511344269857,"bin_end":5.5634999982873286,"count":0},{"bin_start":5.5634999982873286,"bin_end":6.0244886523047985,"count":1}]}},{"name":"repeat_retailer","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"0.8804137774241219","max":"0.8845323070513031","histogram":[{"bin_start":0.8804137774241219,"bin_end":0.88082563038684,"count":1},{"bin_start":0.88082563038684,"bin_end":0.8812374833495581,"count":0},{"bin_start":0.8812374833495581,"bin_end":0.8816493363122763,"count":0},{"bin_start":0.8816493363122763,"bin_end":0.8820611892749943,"count":0},{"bin_start":0.8820611892749943,"bin_end":0.8824730422377125,"count":0},{"bin_start":0.8824730422377125,"bin_end":0.8828848952004307,"count":0},{"bin_start":0.8828848952004307,"bin_end":0.8832967481631487,"count":0},{"bin_start":0.8832967481631487,"bin_end":0.8837086011258669,"count":0},{"bin_start":0.8837086011258669,"bin_end":0.884120454088585,"count":0},{"bin_start":0.884120454088585,"bin_end":0.8845323070513031,"count":1}]}},{"name":"used_chip","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"0.2533818347163806","max":"0.3572908785895201","histogram":[{"bin_start":0.2533818347163806,"bin_end":0.26377273910369453,"count":1},{"bin_start":0.26377273910369453,"bin_end":0.27416364349100847,"count":0},{"bin_start":0.27416364349100847,"bin_end":0.28455454787832246,"count":0},{"bin_start":0.28455454787832246,"bin_end":0.2949454522656364,"count":0},{"bin_start":0.2949454522656364,"bin_end":0.30533635665295034,"count":0},{"bin_start":0.30533635665295034,"bin_end":0.3157272610402643,"count":0},{"bin_start":0.3157272610402643,"bin_end":0.3261181654275782,"count":0},{"bin_start":0.3261181654275782,"bin_end":0.33650906981489215,"count":0},{"bin_start":0.33650906981489215,"bin_end":0.34689997420220614,"count":0},{"bin_start":0.34689997420220614,"bin_end":0.3572908785895201,"count":1}]}},{"name":"used_pin_number","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"0.0028418779129248607","max":"0.11058846748462221","histogram":[{"bin_start":0.0028418779129248607,"bin_end":0.013616536870094596,"count":1},{"bin_start":0.013616536870094596,"bin_end":0.02439119582726433,"count":0},{"bin_start":0.02439119582726433,"bin_end":0.03516585478443406,"count":0},{"bin_start":0.03516585478443406,"bin_end":0.0459405137416038,"count":0},{"bin_start":0.0459405137416038,"bin_end":0.05671517269877354,"count":0},{"bin_start":0.05671517269877354,"bin_end":0.06748983165594327,"count":0},{"bin_start":0.06748983165594327,"bin_end":0.07826449061311301,"count":0},{"bin_start":0.07826449061311301,"bin_end":0.08903914957028275,"count":0},{"bin_start":0.08903914957028275,"bin_end":0.09981380852745249,"count":0},{"bin_start":0.09981380852745249,"bin_end":0.11058846748462221,"count":1}]}},{"name":"online_order","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"0.6213282457813888","max":"0.9457769694213937","histogram":[{"bin_start":0.6213282457813888,"bin_end":0.6537731181453893,"count":1},{"bin_start":0.6537731181453893,"bin_end":0.6862179905093898,"count":0},{"bin_start":0.6862179905093898,"bin_end":0.7186628628733902,"count":0},{"bin_start":0.7186628628733902,"bin_end":0.7511077352373907,"count":0},{"bin_start":0.7511077352373907,"bin_end":0.7835526076013912,"count":0},{"bin_start":0.7835526076013912,"bin_end":0.8159974799653917,"count":0},{"bin_start":0.8159974799653917,"bin_end":0.8484423523293922,"count":0},{"bin_start":0.8484423523293922,"bin_end":0.8808872246933928,"count":0},{"bin_start":0.8808872246933928,"bin_end":0.9133320970573933,"count":0},{"bin_start":0.9133320970573933,"bin_end":0.9457769694213937,"count":1}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows":[{"distance_from_home":67.11251533233086,"distance_from_last_transaction":11.811646222217304,"ratio_to_median_purchase_price":6.0244886523047985,"repeat_retailer":0.8804137774241219,"used_chip":0.2533818347163806,"used_pin_number":0.0028418779129248607,"online_order":0.9457769694213937,"_deepnote_index_column":"Fraud"},{"distance_from_home":22.831175153939462,"distance_from_last_transaction":4.2558134678412065,"ratio_to_median_purchase_price":1.4146021121300856,"repeat_retailer":0.8845323070513031,"used_chip":0.3572908785895201,"used_pin_number":0.11058846748462221,"online_order":0.6213282457813888,"_deepnote_index_column":"Not Fraud"}]},"text/plain":"           distance_from_home  distance_from_last_transaction  \\\nfraud                                                           \nFraud               67.112515                       11.811646   \nNot Fraud           22.831175                        4.255813   \n\n           ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\nfraud                                                                   \nFraud                            6.024489         0.880414   0.253382   \nNot Fraud                        1.414602         0.884532   0.357291   \n\n           used_pin_number  online_order  \nfraud                                     \nFraud             0.002842      0.945777  \nNot Fraud         0.110588      0.621328  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distance_from_home</th>\n      <th>distance_from_last_transaction</th>\n      <th>ratio_to_median_purchase_price</th>\n      <th>repeat_retailer</th>\n      <th>used_chip</th>\n      <th>used_pin_number</th>\n      <th>online_order</th>\n    </tr>\n    <tr>\n      <th>fraud</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Fraud</th>\n      <td>67.112515</td>\n      <td>11.811646</td>\n      <td>6.024489</td>\n      <td>0.880414</td>\n      <td>0.253382</td>\n      <td>0.002842</td>\n      <td>0.945777</td>\n    </tr>\n    <tr>\n      <th>Not Fraud</th>\n      <td>22.831175</td>\n      <td>4.255813</td>\n      <td>1.414602</td>\n      <td>0.884532</td>\n      <td>0.357291</td>\n      <td>0.110588</td>\n      <td>0.621328</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/00cb3c18-2bf7-440b-827e-db0389050d80","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766470,"execution_millis":401,"deepnote_to_be_reexecuted":false,"cell_id":"71d7abdddb404d509b52a51ab60e4b1b","deepnote_cell_type":"code"},"source":"df_train.groupby(\"fraud\").std()","block_group":"4ea4a761d4f342ac929daf852524bb82","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":7,"row_count":2,"columns":[{"name":"distance_from_home","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"50.90599207082166","max":"131.7128893093553","histogram":[{"bin_start":50.90599207082166,"bin_end":58.98668179467502,"count":1},{"bin_start":58.98668179467502,"bin_end":67.06737151852839,"count":0},{"bin_start":67.06737151852839,"bin_end":75.14806124238174,"count":0},{"bin_start":75.14806124238174,"bin_end":83.22875096623511,"count":0},{"bin_start":83.22875096623511,"bin_end":91.30944069008848,"count":0},{"bin_start":91.30944069008848,"bin_end":99.39013041394185,"count":0},{"bin_start":99.39013041394185,"bin_end":107.4708201377952,"count":0},{"bin_start":107.4708201377952,"bin_end":115.55150986164855,"count":0},{"bin_start":115.55150986164855,"bin_end":123.63219958550192,"count":0},{"bin_start":123.63219958550192,"bin_end":131.7128893093553,"count":1}]}},{"name":"distance_from_last_transaction","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"16.16607935006026","max":"42.09671841181561","histogram":[{"bin_start":16.16607935006026,"bin_end":18.759143256235795,"count":1},{"bin_start":18.759143256235795,"bin_end":21.352207162411332,"count":0},{"bin_start":21.352207162411332,"bin_end":23.945271068586866,"count":0},{"bin_start":23.945271068586866,"bin_end":26.5383349747624,"count":0},{"bin_start":26.5383349747624,"bin_end":29.131398880937933,"count":0},{"bin_start":29.131398880937933,"bin_end":31.724462787113467,"count":0},{"bin_start":31.724462787113467,"bin_end":34.317526693289004,"count":0},{"bin_start":34.317526693289004,"bin_end":36.91059059946454,"count":0},{"bin_start":36.91059059946454,"bin_end":39.50365450564007,"count":0},{"bin_start":39.50365450564007,"bin_end":42.09671841181561,"count":1}]}},{"name":"ratio_to_median_purchase_price","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"1.9344483753201633","max":"5.716637864424257","histogram":[{"bin_start":1.9344483753201633,"bin_end":2.312667324230573,"count":1},{"bin_start":2.312667324230573,"bin_end":2.690886273140982,"count":0},{"bin_start":2.690886273140982,"bin_end":3.069105222051392,"count":0},{"bin_start":3.069105222051392,"bin_end":3.447324170961801,"count":0},{"bin_start":3.447324170961801,"bin_end":3.8255431198722105,"count":0},{"bin_start":3.8255431198722105,"bin_end":4.20376206878262,"count":0},{"bin_start":4.20376206878262,"bin_end":4.581981017693029,"count":0},{"bin_start":4.581981017693029,"bin_end":4.960199966603438,"count":0},{"bin_start":4.960199966603438,"bin_end":5.338418915513848,"count":0},{"bin_start":5.338418915513848,"bin_end":5.716637864424257,"count":1}]}},{"name":"repeat_retailer","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"0.31958727244606466","max":"0.32449549709032693","histogram":[{"bin_start":0.31958727244606466,"bin_end":0.3200780949104909,"count":1},{"bin_start":0.3200780949104909,"bin_end":0.3205689173749171,"count":0},{"bin_start":0.3205689173749171,"bin_end":0.3210597398393433,"count":0},{"bin_start":0.3210597398393433,"bin_end":0.32155056230376955,"count":0},{"bin_start":0.32155056230376955,"bin_end":0.32204138476819577,"count":0},{"bin_start":0.32204138476819577,"bin_end":0.32253220723262205,"count":0},{"bin_start":0.32253220723262205,"bin_end":0.32302302969704827,"count":0},{"bin_start":0.32302302969704827,"bin_end":0.3235138521614745,"count":0},{"bin_start":0.3235138521614745,"bin_end":0.3240046746259007,"count":0},{"bin_start":0.3240046746259007,"bin_end":0.32449549709032693,"count":1}]}},{"name":"used_chip","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"0.43497239912033187","max":"0.47920415746200357","histogram":[{"bin_start":0.43497239912033187,"bin_end":0.43939557495449905,"count":1},{"bin_start":0.43939557495449905,"bin_end":0.4438187507886662,"count":0},{"bin_start":0.4438187507886662,"bin_end":0.44824192662283335,"count":0},{"bin_start":0.44824192662283335,"bin_end":0.45266510245700053,"count":0},{"bin_start":0.45266510245700053,"bin_end":0.4570882782911677,"count":0},{"bin_start":0.4570882782911677,"bin_end":0.4615114541253349,"count":0},{"bin_start":0.4615114541253349,"bin_end":0.4659346299595021,"count":0},{"bin_start":0.4659346299595021,"bin_end":0.4703578057936692,"count":0},{"bin_start":0.4703578057936692,"bin_end":0.4747809816278364,"count":0},{"bin_start":0.4747809816278364,"bin_end":0.47920415746200357,"count":1}]}},{"name":"used_pin_number","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"0.0532364894805008","max":"0.3136235590870626","histogram":[{"bin_start":0.0532364894805008,"bin_end":0.07927519644115698,"count":1},{"bin_start":0.07927519644115698,"bin_end":0.10531390340181315,"count":0},{"bin_start":0.10531390340181315,"bin_end":0.13135261036246934,"count":0},{"bin_start":0.13135261036246934,"bin_end":0.1573913173231255,"count":0},{"bin_start":0.1573913173231255,"bin_end":0.1834300242837817,"count":0},{"bin_start":0.1834300242837817,"bin_end":0.20946873124443788,"count":0},{"bin_start":0.20946873124443788,"bin_end":0.23550743820509404,"count":0},{"bin_start":0.23550743820509404,"bin_end":0.2615461451657502,"count":0},{"bin_start":0.2615461451657502,"bin_end":0.2875848521264064,"count":0},{"bin_start":0.2875848521264064,"bin_end":0.3136235590870626,"count":1}]}},{"name":"online_order","dtype":"float64","stats":{"unique_count":2,"nan_count":0,"min":"0.22647013883761807","max":"0.4850587969902648","histogram":[{"bin_start":0.22647013883761807,"bin_end":0.25232900465288277,"count":1},{"bin_start":0.25232900465288277,"bin_end":0.2781878704681474,"count":0},{"bin_start":0.2781878704681474,"bin_end":0.30404673628341206,"count":0},{"bin_start":0.30404673628341206,"bin_end":0.32990560209867675,"count":0},{"bin_start":0.32990560209867675,"bin_end":0.35576446791394145,"count":0},{"bin_start":0.35576446791394145,"bin_end":0.3816233337292061,"count":0},{"bin_start":0.3816233337292061,"bin_end":0.40748219954447074,"count":0},{"bin_start":0.40748219954447074,"bin_end":0.43334106535973543,"count":0},{"bin_start":0.43334106535973543,"bin_end":0.45919993117500013,"count":0},{"bin_start":0.45919993117500013,"bin_end":0.4850587969902648,"count":1}]}},{"name":"_deepnote_index_column","dtype":"object"}],"rows":[{"distance_from_home":131.7128893093553,"distance_from_last_transaction":42.09671841181561,"ratio_to_median_purchase_price":5.716637864424257,"repeat_retailer":0.32449549709032693,"used_chip":0.43497239912033187,"used_pin_number":0.0532364894805008,"online_order":0.22647013883761807,"_deepnote_index_column":"Fraud"},{"distance_from_home":50.90599207082166,"distance_from_last_transaction":16.16607935006026,"ratio_to_median_purchase_price":1.9344483753201633,"repeat_retailer":0.31958727244606466,"used_chip":0.47920415746200357,"used_pin_number":0.3136235590870626,"online_order":0.4850587969902648,"_deepnote_index_column":"Not Fraud"}]},"text/plain":"           distance_from_home  distance_from_last_transaction  \\\nfraud                                                           \nFraud              131.712889                       42.096718   \nNot Fraud           50.905992                       16.166079   \n\n           ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\nfraud                                                                   \nFraud                            5.716638         0.324495   0.434972   \nNot Fraud                        1.934448         0.319587   0.479204   \n\n           used_pin_number  online_order  \nfraud                                     \nFraud             0.053236      0.226470  \nNot Fraud         0.313624      0.485059  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distance_from_home</th>\n      <th>distance_from_last_transaction</th>\n      <th>ratio_to_median_purchase_price</th>\n      <th>repeat_retailer</th>\n      <th>used_chip</th>\n      <th>used_pin_number</th>\n      <th>online_order</th>\n    </tr>\n    <tr>\n      <th>fraud</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Fraud</th>\n      <td>131.712889</td>\n      <td>42.096718</td>\n      <td>5.716638</td>\n      <td>0.324495</td>\n      <td>0.434972</td>\n      <td>0.053236</td>\n      <td>0.226470</td>\n    </tr>\n    <tr>\n      <th>Not Fraud</th>\n      <td>50.905992</td>\n      <td>16.166079</td>\n      <td>1.934448</td>\n      <td>0.319587</td>\n      <td>0.479204</td>\n      <td>0.313624</td>\n      <td>0.485059</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/638bb3a2-9537-4d6e-aed1-e0b22b2981af","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766505,"execution_millis":366,"deepnote_to_be_reexecuted":false,"cell_id":"54bba99075f8408780350d45d0851fff","deepnote_cell_type":"code"},"source":"Gaussian_helper(df_train, 'Fraud', 'distance_from_home')","block_group":"de10fdf8ecb54493ab8033ce02f9a5dd","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"{'mean': 67.11251533233086, 'std': 131.71288930935555}"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/e544f978-45a1-4fb8-adb3-f2b8387e4984","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766543,"execution_millis":329,"deepnote_to_be_reexecuted":false,"cell_id":"cfd596bdbd244e989dc1d4e5a8e4bdc3","deepnote_cell_type":"code"},"source":"Gaussian_helper(df_train, 'Not Fraud', 'distance_from_home')","block_group":"53b5497d9a4249bc892523ccd7dc45bf","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"{'mean': 22.831175153939462, 'std': 50.90599207082154}"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/8b09ebba-66fd-44a6-a5b2-abd9db088b88","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766559,"execution_millis":314,"deepnote_to_be_reexecuted":false,"cell_id":"9e138dd0a64243938f00cfb3129d31c4","deepnote_cell_type":"code"},"source":"Gaussian_helper(df_train, 'Fraud', 'distance_from_last_transaction')","block_group":"d78f516698c34ca1aea2bc0de35d5015","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"{'mean': 11.811646222217306, 'std': 42.09671841181567}"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/80daead3-f2bf-40cb-959d-a3fc48555c4c","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766593,"execution_millis":280,"deepnote_to_be_reexecuted":false,"cell_id":"9a35badb5b064d01b22a30ed4b7a74ab","deepnote_cell_type":"code"},"source":"Gaussian_helper(df_train, 'Not Fraud', 'distance_from_last_transaction')","block_group":"1b422fd4469d415aa52ef0eb62cac1ff","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"{'mean': 4.2558134678412065, 'std': 16.166079350060176}"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/47d7da1b-b97d-4858-97ad-80f6750d3d55","content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"ee2a8b3a63364bef9f8868c3af70bdbd","deepnote_cell_type":"markdown"},"source":"Here is an example of using a dictionary to replace every value in a column.  Think of the values in this dictionary as our estimated probabilities.\n\n```\ntemp_dct = {True: 0.71, False: 0.29}\n\nX_train[\"used_chip\"].map(temp_dct)\n```","block_group":"ece93fa5c92c4e0e82b6f1bb10e2089e"},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"0a8e7b7024df41dcaa89dd970a689d3d","deepnote_cell_type":"markdown"},"source":"Momentarily fix the class $k$ to be \"Fraud\".  We are going to compute the numerator of Equation (4.30) for every row of `X_train`.  (Here we switch back to using `X_train` rather than `df_train`.)\n\nDo all of the following in a single code cell.  (The reason for not separating the cells is so that the entire cell can be run again easily.)\n\n* Assign `k = \"Fraud\"`.\n* Copy the `X_train` DataFrame into a new DataFrame called `X_temp`.  Use the `copy` method.\n* For each column of `X_temp`, use `Gaussian_helper` or `Boolean_helper`, as appropriate, to replace each value $x_i$ with $f(x_i)$, where $f$ is as in (4.30).  You can use a for loop to loop over the columns, but within a fixed column, you should not need to use a for loop (in other words, you should not need to loop over the rows, only over the columns).  The following imports might be helpful for determining the data types (make the imports outside of any for loop).\n```\nfrom pandas.api.types import is_bool_dtype, is_float_dtype\n```\n\nComment: Your code should be changing the `X_temp` entries but not the `X_train` entries.  When you are finished, `X_temp` will be a DataFrame containing probabilities, all corresponding to the \"Fraud\" class.\n\n* For each row, multiply all entries in that row.  (Hint.  DataFrames have a `prod` method.)  Also multiply by the prior probability of \"Fraud\".  (Use `k`, do not type `\"Fraud\"`.)  The end result should be a pandas Series corresponding to the numerator of (4.30), for each row of `X_train`.  Don't be surprised if the numbers are very small, like around $10^{-10}$.","block_group":"9bfafd0c01764c4da0b11ad7b4cb14fa"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766594,"execution_millis":280,"deepnote_to_be_reexecuted":false,"cell_id":"c1e69a71c9514d518d144a46c2e35417","deepnote_cell_type":"code"},"source":"def bool_func(df_train, col,k):\n    mydf = df_train[df_train['fraud'] == k]\n\n    true = len(mydf[mydf[col] == True])/len(mydf)\n    false = 1-true\n\n    temp_dct = {True: true, False: false}\n\n    myser = df_train[col].map(temp_dct)\n\n    return myser    ","block_group":"3a39c2422f7f494ab26379d9076e8819","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766594,"execution_millis":280,"deepnote_to_be_reexecuted":false,"cell_id":"8df9ff06007a4c57b35ebf420dc1658e","deepnote_cell_type":"code"},"source":"def float_func(df_train, col,k):\n    mydf = df_train[df_train['fraud'] == k]\n\n    mu = mydf[col].mean()\n    sig = mydf[col].std()\n\n    mylist = []\n    for x in df_train[col]:\n        p = st.norm.pdf(x, loc = mu, scale = sig)\n        mylist.append(p)\n\n    return mylist","block_group":"c5b95e50d66e4c6395936d7ca969c4f3","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766595,"execution_millis":280,"deepnote_to_be_reexecuted":false,"cell_id":"dda3b2ec2d5e4ed0b6f5a3d93e618c67","deepnote_cell_type":"code"},"source":"df_sub = df_train.copy()\ndf_sub['fraud'].map(prior_dct)","block_group":"51afb67ffe3f4af480b47c02c624e8f3","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"444737    0.91203\n957507    0.08797\n277798    0.91203\n817894    0.91203\n911671    0.91203\n           ...   \n359761    0.91203\n728155    0.91203\n808016    0.91203\n822975    0.91203\n403353    0.91203\nName: fraud, Length: 100000, dtype: float64"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/bd0a2248-fd0a-47c0-9138-a4628a9640d0","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087766645,"execution_millis":39870,"deepnote_to_be_reexecuted":false,"cell_id":"4512da9ac0de420080e5929912e14071","deepnote_cell_type":"code"},"source":"from pandas.api.types import is_bool_dtype, is_float_dtype\nk = \"Fraud\"\n\ndf_temp = df_train.copy()  #has fraud col\nX_temp = X_train.copy()  #no fradu col\n\n\nfor col in X_temp.columns:\n\n    if is_bool_dtype(X_temp[col]) == True:\n        df_temp[col] = bool_func(df_temp, col,k)\n\n    else:\n        df_temp[col] = float_func(df_temp, col,k)\n\n\ndf_temp[\"fraud\"] = df_temp[\"fraud\"].map(prior_dct)\ndf_temp.prod(axis=1,numeric_only=True)","block_group":"847e0bcdd4114b94a378c4286aa6d930","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"444737    3.486877e-08\n957507    3.581686e-09\n277798    5.784414e-11\n817894    4.612560e-09\n911671    3.441176e-08\n              ...     \n359761    5.559158e-08\n728155    2.341414e-09\n808016    4.325602e-08\n822975    2.760669e-08\n403353    6.529805e-07\nLength: 100000, dtype: float64"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/f99b7093-0042-4af6-bb2a-74d82225a097","content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"48549d4f787b4fa3af6857fa65531c96","deepnote_cell_type":"markdown"},"source":"* Once the code is working, wrap the whole thing into another for loop, corresponding to `k = \"Fraud\"` and `k = \"Not Fraud\"`, putting the two resulting pandas Series into a length 2 dictionary with keys `\"Fraud\"` and `\"Not Fraud\"`.  Call this dictionary `num_dct`, because it represents the numerators of (4.30).","block_group":"87d22b842c514ffea95668c2c85cfa85"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087806563,"execution_millis":82488,"deepnote_to_be_reexecuted":false,"cell_id":"8b0e295845c84953b08c15dd6d89f596","deepnote_cell_type":"code"},"source":"num_dct = {}\n\nfor k in ['Fraud', 'Not Fraud']:\n\n    df_temp = df_train.copy()  #has fraud col\n    X_temp = X_train.copy()  #no fradu col\n\n    for col in X_temp.columns:\n\n        if is_bool_dtype(X_temp[col]) == True:\n            df_temp[col] = bool_func(df_temp, col,k)\n\n        else:\n            df_temp[col] = float_func(df_temp, col,k)\n    df_temp[\"fraud\"] = df_temp[\"fraud\"].map(prior_dct)\n    num_dct[k] = df_temp.prod(axis=1,numeric_only=True)\n\nnum_dct","block_group":"cf4e57517d0c415ba72b4d6b863af92d","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"{'Fraud': 444737    3.486877e-08\n 957507    3.581686e-09\n 277798    5.784414e-11\n 817894    4.612560e-09\n 911671    3.441176e-08\n               ...     \n 359761    5.559158e-08\n 728155    2.341414e-09\n 808016    4.325602e-08\n 822975    2.760669e-08\n 403353    6.529805e-07\n Length: 100000, dtype: float64,\n 'Not Fraud': 444737    5.648824e-06\n 957507    6.010885e-11\n 277798    7.733600e-08\n 817894    7.014100e-07\n 911671    5.327139e-06\n               ...     \n 359761    2.016076e-06\n 728155    1.277531e-06\n 808016    6.103287e-06\n 822975    6.529298e-07\n 403353    5.692318e-06\n Length: 100000, dtype: float64}"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/8611b4e8-264d-442e-94e9-0f32be2e3fc8","content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"c69ca20745ba451b9523f1942e4fbfd3","deepnote_cell_type":"markdown"},"source":"* Create a new two-column pandas DataFrame with the results using the following code:\n```\ndf_num = pd.DataFrame(num_dct)\n```","block_group":"9b2a0089105f49b594239c8f35758b63"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087889095,"execution_millis":315,"deepnote_to_be_reexecuted":false,"cell_id":"86b489e147bb49ec928fb53fb2e2e703","deepnote_cell_type":"code"},"source":"df_num = pd.DataFrame(num_dct)","block_group":"8745a8147b4e421aa1091b3090164ab8","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087889096,"execution_millis":315,"deepnote_to_be_reexecuted":false,"cell_id":"d95b22286a484d3eaad75306830c970f","deepnote_cell_type":"code"},"source":"df_num","block_group":"b77ec54f1d1e4e63acf2fd1d3fd80564","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":2,"row_count":100000,"columns":[{"name":"Fraud","dtype":"float64","stats":{"unique_count":100000,"nan_count":0,"min":"1.931463299520017e-287","max":"1.0549259754188897e-06","histogram":[{"bin_start":1.931463299520017e-287,"bin_end":1.0549259754188897e-7,"count":55587},{"bin_start":1.0549259754188897e-7,"bin_end":2.1098519508377794e-7,"count":4156},{"bin_start":2.1098519508377794e-7,"bin_end":3.164777926256669e-7,"count":11765},{"bin_start":3.164777926256669e-7,"bin_end":4.2197039016755587e-7,"count":343},{"bin_start":4.2197039016755587e-7,"bin_end":5.274629877094449e-7,"count":89},{"bin_start":5.274629877094449e-7,"bin_end":6.329555852513338e-7,"count":7599},{"bin_start":6.329555852513338e-7,"bin_end":7.384481827932228e-7,"count":12100},{"bin_start":7.384481827932228e-7,"bin_end":8.439407803351117e-7,"count":5318},{"bin_start":8.439407803351117e-7,"bin_end":9.494333778770007e-7,"count":2640},{"bin_start":9.494333778770007e-7,"bin_end":0.0000010549259754188897,"count":403}]}},{"name":"Not Fraud","dtype":"float64"},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"Fraud":3.486877087041835e-8,"Not Fraud":0.0000056488238128781085,"_deepnote_index_column":444737},{"Fraud":3.581685527626537e-9,"Not Fraud":6.010884817277515e-11,"_deepnote_index_column":957507},{"Fraud":5.7844136811134e-11,"Not Fraud":7.733600062124235e-8,"_deepnote_index_column":277798},{"Fraud":4.61256008230393e-9,"Not Fraud":7.014099808568458e-7,"_deepnote_index_column":817894},{"Fraud":3.44117574365546e-8,"Not Fraud":0.000005327138772748396,"_deepnote_index_column":911671},{"Fraud":6.218312822567505e-7,"Not Fraud":0.000009495079623053915,"_deepnote_index_column":653863},{"Fraud":5.652917557802871e-8,"Not Fraud":0.000002283701897887327,"_deepnote_index_column":7125},{"Fraud":6.199876507732558e-10,"Not Fraud":2.8165718651689545e-17,"_deepnote_index_column":324101},{"Fraud":8.602989309053874e-7,"Not Fraud":0.000007268212720585827,"_deepnote_index_column":240132},{"Fraud":9.537118162057557e-7,"Not Fraud":0.000006509982452501192,"_deepnote_index_column":333153}]},"text/plain":"               Fraud     Not Fraud\n444737  3.486877e-08  5.648824e-06\n957507  3.581686e-09  6.010885e-11\n277798  5.784414e-11  7.733600e-08\n817894  4.612560e-09  7.014100e-07\n911671  3.441176e-08  5.327139e-06\n...              ...           ...\n359761  5.559158e-08  2.016076e-06\n728155  2.341414e-09  1.277531e-06\n808016  4.325602e-08  6.103287e-06\n822975  2.760669e-08  6.529298e-07\n403353  6.529805e-07  5.692318e-06\n\n[100000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Fraud</th>\n      <th>Not Fraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>444737</th>\n      <td>3.486877e-08</td>\n      <td>5.648824e-06</td>\n    </tr>\n    <tr>\n      <th>957507</th>\n      <td>3.581686e-09</td>\n      <td>6.010885e-11</td>\n    </tr>\n    <tr>\n      <th>277798</th>\n      <td>5.784414e-11</td>\n      <td>7.733600e-08</td>\n    </tr>\n    <tr>\n      <th>817894</th>\n      <td>4.612560e-09</td>\n      <td>7.014100e-07</td>\n    </tr>\n    <tr>\n      <th>911671</th>\n      <td>3.441176e-08</td>\n      <td>5.327139e-06</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>359761</th>\n      <td>5.559158e-08</td>\n      <td>2.016076e-06</td>\n    </tr>\n    <tr>\n      <th>728155</th>\n      <td>2.341414e-09</td>\n      <td>1.277531e-06</td>\n    </tr>\n    <tr>\n      <th>808016</th>\n      <td>4.325602e-08</td>\n      <td>6.103287e-06</td>\n    </tr>\n    <tr>\n      <th>822975</th>\n      <td>2.760669e-08</td>\n      <td>6.529298e-07</td>\n    </tr>\n    <tr>\n      <th>403353</th>\n      <td>6.529805e-07</td>\n      <td>5.692318e-06</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/cea83380-19f8-46d1-81ef-3e34e68aad4e","content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087889211,"execution_millis":2295,"deepnote_table_state":{"sortBy":[],"filters":[],"pageSize":10,"pageIndex":0},"deepnote_table_loading":false,"deepnote_to_be_reexecuted":false,"cell_id":"d214d6aff72b4ed0bdf7483c5f595e7d","deepnote_cell_type":"code"},"source":"clf = []\nfor i in range(len(df_num.index)):\n    fraud = df_num['Fraud'].iloc[i]\n    not_fraud = df_num[\"Not Fraud\"].iloc[i]\n    \n    if fraud > not_fraud:\n        clf.append(\"Fraud\")\n    else:\n        clf.append(\"Not Fraud\")\ndf_num['type'] = clf","block_group":"fc7b9072dfdc45d9a0761639d5809d5f","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087891514,"execution_millis":242,"deepnote_to_be_reexecuted":false,"cell_id":"dcae6cb48e224cb58068f22612391520","deepnote_cell_type":"code"},"source":"df_train['predict'] = clf\ndf_train","block_group":"1b6952736fa74d75a632c3eb01c01c8f","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"application/vnd.deepnote.dataframe.v3+json":{"column_count":9,"row_count":100000,"columns":[{"name":"distance_from_home","dtype":"float64","stats":{"unique_count":100000,"nan_count":0,"min":"0.0318721767498711","max":"3509.712374010665","histogram":[{"bin_start":0.0318721767498711,"bin_end":350.99992236014134,"count":99416},{"bin_start":350.99992236014134,"bin_end":701.9679725435328,"count":472},{"bin_start":701.9679725435328,"bin_end":1052.9360227269244,"count":70},{"bin_start":1052.9360227269244,"bin_end":1403.9040729103158,"count":17},{"bin_start":1403.9040729103158,"bin_end":1754.8721230937072,"count":12},{"bin_start":1754.8721230937072,"bin_end":2105.840173277099,"count":7},{"bin_start":2105.840173277099,"bin_end":2456.8082234604904,"count":4},{"bin_start":2456.8082234604904,"bin_end":2807.7762736438817,"count":1},{"bin_start":2807.7762736438817,"bin_end":3158.744323827273,"count":0},{"bin_start":3158.744323827273,"bin_end":3509.712374010665,"count":1}]}},{"name":"distance_from_last_transaction","dtype":"float64"},{"name":"ratio_to_median_purchase_price","dtype":"float64"},{"name":"repeat_retailer","dtype":"bool"},{"name":"used_chip","dtype":"bool"},{"name":"used_pin_number","dtype":"bool"},{"name":"online_order","dtype":"bool"},{"name":"fraud","dtype":"object"},{"name":"predict","dtype":"object"},{"name":"_deepnote_index_column","dtype":"int64"}],"rows":[{"distance_from_home":8.20254779683263,"distance_from_last_transaction":0.273947264983326,"ratio_to_median_purchase_price":0.3991240329181347,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","predict":"Not Fraud","_deepnote_index_column":444737},{"distance_from_home":202.48673621301648,"distance_from_last_transaction":1.4861936663765254,"ratio_to_median_purchase_price":6.21527650026276,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Fraud","predict":"Fraud","_deepnote_index_column":957507},{"distance_from_home":23.97438153639849,"distance_from_last_transaction":4.302344391330343,"ratio_to_median_purchase_price":5.113708147235172,"repeat_retailer":"True","used_chip":"True","used_pin_number":"True","online_order":"False","fraud":"Not Fraud","predict":"Not Fraud","_deepnote_index_column":277798},{"distance_from_home":1.050778204657945,"distance_from_last_transaction":0.5638268768547423,"ratio_to_median_purchase_price":0.3842818390812081,"repeat_retailer":"False","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","predict":"Not Fraud","_deepnote_index_column":817894},{"distance_from_home":2.426653457659478,"distance_from_last_transaction":6.746157724756723,"ratio_to_median_purchase_price":0.2674120680794355,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","predict":"Not Fraud","_deepnote_index_column":911671},{"distance_from_home":3.366991942526937,"distance_from_last_transaction":0.270906678561351,"ratio_to_median_purchase_price":0.6322041735168126,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"True","fraud":"Not Fraud","predict":"Not Fraud","_deepnote_index_column":653863},{"distance_from_home":23.357591803698423,"distance_from_last_transaction":0.4862674057227584,"ratio_to_median_purchase_price":4.267920252395248,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","predict":"Not Fraud","_deepnote_index_column":7125},{"distance_from_home":60.42968206398348,"distance_from_last_transaction":119.41101375798264,"ratio_to_median_purchase_price":1.5752884076515314,"repeat_retailer":"True","used_chip":"True","used_pin_number":"False","online_order":"False","fraud":"Not Fraud","predict":"Fraud","_deepnote_index_column":324101},{"distance_from_home":7.296625371219279,"distance_from_last_transaction":0.0033144192635508,"ratio_to_median_purchase_price":3.0817649582440145,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"True","fraud":"Not Fraud","predict":"Not Fraud","_deepnote_index_column":240132},{"distance_from_home":20.47990510577761,"distance_from_last_transaction":6.7446837855175845,"ratio_to_median_purchase_price":3.4430804736624245,"repeat_retailer":"True","used_chip":"False","used_pin_number":"False","online_order":"True","fraud":"Not Fraud","predict":"Not Fraud","_deepnote_index_column":333153}]},"text/plain":"        distance_from_home  distance_from_last_transaction  \\\n444737            8.202548                        0.273947   \n957507          202.486736                        1.486194   \n277798           23.974382                        4.302344   \n817894            1.050778                        0.563827   \n911671            2.426653                        6.746158   \n...                    ...                             ...   \n359761           15.735257                        0.031037   \n728155           12.747647                        4.710128   \n808016            3.012602                        1.074755   \n822975            1.097913                        1.730297   \n403353           72.758811                        0.073200   \n\n        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n444737                        0.399124             True      False   \n957507                        6.215277             True      False   \n277798                        5.113708             True       True   \n817894                        0.384282            False      False   \n911671                        0.267412             True      False   \n...                                ...              ...        ...   \n359761                        4.406235             True      False   \n728155                        2.218541             True      False   \n808016                        1.939998             True      False   \n822975                        0.406524            False       True   \n403353                        0.245930             True      False   \n\n        used_pin_number  online_order      fraud    predict  \n444737            False         False  Not Fraud  Not Fraud  \n957507            False         False      Fraud      Fraud  \n277798             True         False  Not Fraud  Not Fraud  \n817894            False         False  Not Fraud  Not Fraud  \n911671            False         False  Not Fraud  Not Fraud  \n...                 ...           ...        ...        ...  \n359761            False         False  Not Fraud  Not Fraud  \n728155             True          True  Not Fraud  Not Fraud  \n808016            False         False  Not Fraud  Not Fraud  \n822975            False          True  Not Fraud  Not Fraud  \n403353            False          True  Not Fraud  Not Fraud  \n\n[100000 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>distance_from_home</th>\n      <th>distance_from_last_transaction</th>\n      <th>ratio_to_median_purchase_price</th>\n      <th>repeat_retailer</th>\n      <th>used_chip</th>\n      <th>used_pin_number</th>\n      <th>online_order</th>\n      <th>fraud</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>444737</th>\n      <td>8.202548</td>\n      <td>0.273947</td>\n      <td>0.399124</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>957507</th>\n      <td>202.486736</td>\n      <td>1.486194</td>\n      <td>6.215277</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Fraud</td>\n      <td>Fraud</td>\n    </tr>\n    <tr>\n      <th>277798</th>\n      <td>23.974382</td>\n      <td>4.302344</td>\n      <td>5.113708</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>817894</th>\n      <td>1.050778</td>\n      <td>0.563827</td>\n      <td>0.384282</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>911671</th>\n      <td>2.426653</td>\n      <td>6.746158</td>\n      <td>0.267412</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>359761</th>\n      <td>15.735257</td>\n      <td>0.031037</td>\n      <td>4.406235</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>728155</th>\n      <td>12.747647</td>\n      <td>4.710128</td>\n      <td>2.218541</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Not Fraud</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>808016</th>\n      <td>3.012602</td>\n      <td>1.074755</td>\n      <td>1.939998</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Not Fraud</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>822975</th>\n      <td>1.097913</td>\n      <td>1.730297</td>\n      <td>0.406524</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Not Fraud</td>\n      <td>Not Fraud</td>\n    </tr>\n    <tr>\n      <th>403353</th>\n      <td>72.758811</td>\n      <td>0.073200</td>\n      <td>0.245930</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Not Fraud</td>\n      <td>Not Fraud</td>\n    </tr>\n  </tbody>\n</table>\n<p>100000 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}],"outputs_reference":"s3:deepnote-cell-outputs-production/8ca6f677-c3a1-4e4c-86c6-5ac4a31bbc86","content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"bd4ef05e10f9431a9d2daf3ea5e3f6d6","deepnote_cell_type":"markdown"},"source":"* What proportion of the values in `X_train` are correctly identified as Fraud using this procedure?  (Note.  We never actually need to compute the denominator in (4.30), since all we care about here is which entry is bigger.)","block_group":"dbdf7dbe2b7f4e83876ed66ea353a5df"},{"cell_type":"code","metadata":{"source_hash":null,"execution_start":1714087891620,"execution_millis":2165,"deepnote_to_be_reexecuted":false,"cell_id":"1210604fcc1b49dcaa654e15c119129e","deepnote_cell_type":"code"},"source":"wrong = 0\nfor i in range(len(df_train.index)):\n    act = df_train['fraud'].iloc[i]\n    predict = df_train['predict'].iloc[i]\n    if act != predict:\n        wrong += 1\n\n1 - wrong/len(df_train.index)","block_group":"a7d546298827484eabafb8078d30f256","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"0.9359500000000001"},"metadata":{}}],"outputs_reference":"dbtable:cell_outputs/3e6f4a1f-b323-43c5-8bfb-7056402ba347","content_dependencies":null},{"cell_type":"markdown","metadata":{"deepnote_app_block_visible":false,"cell_id":"b950cf4ce3b04dfba921c43a84466ebf","deepnote_cell_type":"markdown"},"source":"## Submission\n\n* Using the `Share` button at the top right, enable public sharing, and enable Comment privileges. Then submit the created link on Canvas.","block_group":"8355e878f0244309b7d7690a7a5c0764"},{"cell_type":"markdown","metadata":{"cell_id":"52c45d83e027467b97bb0a0ebf609281","deepnote_cell_type":"markdown"},"source":"## Possible extensions\n\n* I originally wanted us to consider log loss as our error metric, but I decided the lab was already getting rather long, so I removed that.  But in general, log loss is a more refined measure for detecting overfitting than accuracy score.  It should be relatively straightforward to evaluate log loss for the Logistic Regression model.  Compare this to the log loss of a baseline prediction, where we predict the same probability for every row.  I got some errors when I tried to evaluate log loss for the Naive Bayes model and I haven't thought carefully about how to avoid these.\n* How do our values compare to using the scikit-learn Naive Bayes model?  (I don't think this will be easy, because you will have to treat the Gaussian and the Boolean portions separately.  There might also be some discrepancy due to our method of estimating standard deviation, but I don't think that is crucial.  I have not tried this myself, so there could also be other discrepancies I'm not anticipating.)\n* How does KNN compare in performance?  (What's the optimal number of neighbors?)  I haven't tried this, and I think the training size might be too large, so be prepared to reduce the size of the training set further.","block_group":"7d5fe7c432954a9a8075c0b04bbb47a4"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=c7576d13-6fc0-4627-81ec-ac1ef6a08f48' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"3d49f46a1a174686a54326851f938e53","deepnote_execution_queue":[]}}